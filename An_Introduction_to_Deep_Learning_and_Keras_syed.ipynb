{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X2GfsHawdo6T"
      },
      "source": [
        "# Learn Keras for Deep Neural Networks\n",
        "## An Introduction to Deep Learning and Keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pcu8QGukdo6Z"
      },
      "source": [
        "A sneak peek in the Keras Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "no1z01DtecsC"
      },
      "outputs": [],
      "source": [
        "#Import required packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "m-Z5xgoueeDa"
      },
      "outputs": [],
      "source": [
        "# Getting the data ready\n",
        "# Generate train dummy data for 1000 Students and dummy test for 500\n",
        "#Columns :Age, Hours of Study & Avg Previous test scores\n",
        "np.random.seed(2018)\n",
        "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
        "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
        "labels = np.random.randint(2, size=(1000, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "colab_type": "code",
        "id": "Wjhagy9PeeM6",
        "outputId": "5acc00f5-fb32-44a3-a623-86a7828d67f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.88234931, 0.10432774, 0.90700933],\n",
              "       [0.3063989 , 0.44640887, 0.58998539],\n",
              "       [0.8371111 , 0.69780061, 0.80280284],\n",
              "       ...,\n",
              "       [0.76474832, 0.12224649, 0.06019634],\n",
              "       [0.21847107, 0.57064847, 0.27701246],\n",
              "       [0.97785211, 0.81210972, 0.34780075]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "colab_type": "code",
        "id": "KmocBhvleeUB",
        "outputId": "d305c87a-1614-45aa-9b8e-495af86c5fad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.35981783, 0.64707122, 0.16858627],\n",
              "       [0.95089881, 0.24401454, 0.39478811],\n",
              "       [0.99185888, 0.01995682, 0.19105642],\n",
              "       ...,\n",
              "       [0.03335012, 0.35559007, 0.5386409 ],\n",
              "       [0.3804594 , 0.11970055, 0.08783101],\n",
              "       [0.83887832, 0.26936355, 0.90847875]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vTveQsSXeeW5"
      },
      "outputs": [],
      "source": [
        "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=3, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "colab_type": "code",
        "id": "0dQeCXefeeZZ",
        "outputId": "21406510-3848-4cd9-c34f-371b5c182aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 5)                 20        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 24        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49\n",
            "Trainable params: 49\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "colab_type": "code",
        "id": "rcEFnRqZeecw",
        "outputId": "0386e658-ecee-4a5b-bd05-aa16e3043057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 2s 6ms/step - loss: 0.6965 - accuracy: 0.4970\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6952 - accuracy: 0.5020\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5120\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.4910\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.4960\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.4860\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.4850\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.4930\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.4930\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.4930\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52b4495510>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Train the model and make predictions\n",
        "model.fit(train_data, labels, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Do-TqfJigND0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "#Make predictions from the trained model\n",
        "predictions = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "mTnDMknAgUpX",
        "outputId": "e3ce8a34-e3f0-4e33-e772-63f990801c6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.49504074],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4884657 ],\n",
              "       [0.5078338 ],\n",
              "       [0.49037918],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4962441 ],\n",
              "       [0.48787293],\n",
              "       [0.49300972],\n",
              "       [0.500146  ],\n",
              "       [0.4934273 ],\n",
              "       [0.5087889 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50126404],\n",
              "       [0.49425742],\n",
              "       [0.50215757],\n",
              "       [0.50161123],\n",
              "       [0.4999982 ],\n",
              "       [0.48866633],\n",
              "       [0.5177535 ],\n",
              "       [0.48628438],\n",
              "       [0.49882916],\n",
              "       [0.4859416 ],\n",
              "       [0.48913574],\n",
              "       [0.5073065 ],\n",
              "       [0.4987795 ],\n",
              "       [0.4917665 ],\n",
              "       [0.5119133 ],\n",
              "       [0.4884134 ],\n",
              "       [0.50185037],\n",
              "       [0.50270295],\n",
              "       [0.49295235],\n",
              "       [0.5048602 ],\n",
              "       [0.48788613],\n",
              "       [0.49700415],\n",
              "       [0.5052407 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5132614 ],\n",
              "       [0.5084756 ],\n",
              "       [0.5110027 ],\n",
              "       [0.50020885],\n",
              "       [0.50708026],\n",
              "       [0.48857826],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4978909 ],\n",
              "       [0.4992106 ],\n",
              "       [0.5045091 ],\n",
              "       [0.4954565 ],\n",
              "       [0.4859416 ],\n",
              "       [0.48631904],\n",
              "       [0.4922062 ],\n",
              "       [0.506162  ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50104165],\n",
              "       [0.50472265],\n",
              "       [0.50574136],\n",
              "       [0.49201825],\n",
              "       [0.4862321 ],\n",
              "       [0.49744356],\n",
              "       [0.4859416 ],\n",
              "       [0.4990848 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50555444],\n",
              "       [0.5036827 ],\n",
              "       [0.50728995],\n",
              "       [0.4887061 ],\n",
              "       [0.49500746],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49596146],\n",
              "       [0.48962405],\n",
              "       [0.50675285],\n",
              "       [0.4859416 ],\n",
              "       [0.49533683],\n",
              "       [0.4859416 ],\n",
              "       [0.51829684],\n",
              "       [0.4871049 ],\n",
              "       [0.50324756],\n",
              "       [0.49232396],\n",
              "       [0.4859416 ],\n",
              "       [0.49299338],\n",
              "       [0.4859416 ],\n",
              "       [0.49300164],\n",
              "       [0.50975096],\n",
              "       [0.4921276 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5302421 ],\n",
              "       [0.49962634],\n",
              "       [0.5110634 ],\n",
              "       [0.4867046 ],\n",
              "       [0.48722476],\n",
              "       [0.4999427 ],\n",
              "       [0.49164772],\n",
              "       [0.49518508],\n",
              "       [0.51926464],\n",
              "       [0.4859416 ],\n",
              "       [0.4992396 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4947098 ],\n",
              "       [0.4929765 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49193272],\n",
              "       [0.4859416 ],\n",
              "       [0.48697013],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5081211 ],\n",
              "       [0.49992752],\n",
              "       [0.4859416 ],\n",
              "       [0.51326096],\n",
              "       [0.50405777],\n",
              "       [0.4859416 ],\n",
              "       [0.4993441 ],\n",
              "       [0.49712223],\n",
              "       [0.48781374],\n",
              "       [0.5055944 ],\n",
              "       [0.48941138],\n",
              "       [0.4859416 ],\n",
              "       [0.5059293 ],\n",
              "       [0.48644558],\n",
              "       [0.4859416 ],\n",
              "       [0.5003228 ],\n",
              "       [0.5104403 ],\n",
              "       [0.4965614 ],\n",
              "       [0.49526373],\n",
              "       [0.49496394],\n",
              "       [0.4859416 ],\n",
              "       [0.50176454],\n",
              "       [0.4859416 ],\n",
              "       [0.49927455],\n",
              "       [0.4914557 ],\n",
              "       [0.48708507],\n",
              "       [0.4859416 ],\n",
              "       [0.512174  ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4943835 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49200508],\n",
              "       [0.4898986 ],\n",
              "       [0.5248075 ],\n",
              "       [0.49847   ],\n",
              "       [0.4859416 ],\n",
              "       [0.48858643],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4901408 ],\n",
              "       [0.4908493 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49980092],\n",
              "       [0.49162415],\n",
              "       [0.4943064 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50083464],\n",
              "       [0.4859416 ],\n",
              "       [0.49507138],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49761376],\n",
              "       [0.50944567],\n",
              "       [0.51443195],\n",
              "       [0.49480122],\n",
              "       [0.4859416 ],\n",
              "       [0.492956  ],\n",
              "       [0.49354836],\n",
              "       [0.48897746],\n",
              "       [0.5030698 ],\n",
              "       [0.4965545 ],\n",
              "       [0.5060721 ],\n",
              "       [0.4977079 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50106555],\n",
              "       [0.5058428 ],\n",
              "       [0.48678195],\n",
              "       [0.49518353],\n",
              "       [0.4919317 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5058273 ],\n",
              "       [0.49147493],\n",
              "       [0.49590737],\n",
              "       [0.4906954 ],\n",
              "       [0.49073806],\n",
              "       [0.4899579 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49336153],\n",
              "       [0.49310872],\n",
              "       [0.49321905],\n",
              "       [0.4960903 ],\n",
              "       [0.5120632 ],\n",
              "       [0.48922226],\n",
              "       [0.4859416 ],\n",
              "       [0.48728058],\n",
              "       [0.4878838 ],\n",
              "       [0.49837688],\n",
              "       [0.5006077 ],\n",
              "       [0.5091724 ],\n",
              "       [0.50920576],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5007399 ],\n",
              "       [0.4974948 ],\n",
              "       [0.50676566],\n",
              "       [0.4859416 ],\n",
              "       [0.50528514],\n",
              "       [0.49367306],\n",
              "       [0.5055308 ],\n",
              "       [0.50275123],\n",
              "       [0.5130351 ],\n",
              "       [0.49666685],\n",
              "       [0.5029962 ],\n",
              "       [0.49352267],\n",
              "       [0.5006659 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50431836],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5244223 ],\n",
              "       [0.5005937 ],\n",
              "       [0.48930684],\n",
              "       [0.5027387 ],\n",
              "       [0.48650607],\n",
              "       [0.49120194],\n",
              "       [0.49224567],\n",
              "       [0.4898261 ],\n",
              "       [0.49458712],\n",
              "       [0.5193053 ],\n",
              "       [0.48600635],\n",
              "       [0.4877526 ],\n",
              "       [0.487421  ],\n",
              "       [0.49122125],\n",
              "       [0.491179  ],\n",
              "       [0.5067963 ],\n",
              "       [0.48748308],\n",
              "       [0.4987607 ],\n",
              "       [0.49822485],\n",
              "       [0.48788503],\n",
              "       [0.49225494],\n",
              "       [0.49145275],\n",
              "       [0.50381815],\n",
              "       [0.50676084],\n",
              "       [0.50636214],\n",
              "       [0.4859416 ],\n",
              "       [0.4977965 ],\n",
              "       [0.48611858],\n",
              "       [0.4859416 ],\n",
              "       [0.48730376],\n",
              "       [0.5087116 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50162804],\n",
              "       [0.5080844 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49126878],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5045229 ],\n",
              "       [0.4859416 ],\n",
              "       [0.52227825],\n",
              "       [0.49244162],\n",
              "       [0.50105613],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5097112 ],\n",
              "       [0.5035973 ],\n",
              "       [0.49691233],\n",
              "       [0.49915162],\n",
              "       [0.4893423 ],\n",
              "       [0.4859416 ],\n",
              "       [0.491325  ],\n",
              "       [0.49457672],\n",
              "       [0.51051927],\n",
              "       [0.5013211 ],\n",
              "       [0.49919018],\n",
              "       [0.490812  ],\n",
              "       [0.492865  ],\n",
              "       [0.49485338],\n",
              "       [0.5056386 ],\n",
              "       [0.49042803],\n",
              "       [0.5016863 ],\n",
              "       [0.4882358 ],\n",
              "       [0.5083775 ],\n",
              "       [0.49308184],\n",
              "       [0.4981212 ],\n",
              "       [0.48857635],\n",
              "       [0.48670834],\n",
              "       [0.5022981 ],\n",
              "       [0.4991047 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4994391 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4970569 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5123579 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50766796],\n",
              "       [0.49091274],\n",
              "       [0.48692936],\n",
              "       [0.4859416 ],\n",
              "       [0.49548808],\n",
              "       [0.50181574],\n",
              "       [0.4859416 ],\n",
              "       [0.49331367],\n",
              "       [0.4870687 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5058893 ],\n",
              "       [0.4930311 ],\n",
              "       [0.50068533],\n",
              "       [0.4970081 ],\n",
              "       [0.49196157],\n",
              "       [0.4859416 ],\n",
              "       [0.50064796],\n",
              "       [0.5058648 ],\n",
              "       [0.51449734],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50251955],\n",
              "       [0.5007339 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50143015],\n",
              "       [0.5102461 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5140317 ],\n",
              "       [0.507278  ],\n",
              "       [0.5109574 ],\n",
              "       [0.49461025],\n",
              "       [0.4971883 ],\n",
              "       [0.49702713],\n",
              "       [0.5099244 ],\n",
              "       [0.49646226],\n",
              "       [0.501352  ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.48757893],\n",
              "       [0.5010811 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49404377],\n",
              "       [0.48769215],\n",
              "       [0.506676  ],\n",
              "       [0.48605692],\n",
              "       [0.48807105],\n",
              "       [0.4859416 ],\n",
              "       [0.49192455],\n",
              "       [0.50684804],\n",
              "       [0.49794972],\n",
              "       [0.4958803 ],\n",
              "       [0.48907003],\n",
              "       [0.51679754],\n",
              "       [0.5094017 ],\n",
              "       [0.5204828 ],\n",
              "       [0.49478993],\n",
              "       [0.4859416 ],\n",
              "       [0.5031894 ],\n",
              "       [0.49721578],\n",
              "       [0.4859416 ],\n",
              "       [0.48671418],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5123861 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49628374],\n",
              "       [0.4859416 ],\n",
              "       [0.49321383],\n",
              "       [0.49402985],\n",
              "       [0.4859416 ],\n",
              "       [0.4860857 ],\n",
              "       [0.49456128],\n",
              "       [0.5116717 ],\n",
              "       [0.4865095 ],\n",
              "       [0.4929938 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49387395],\n",
              "       [0.50736314],\n",
              "       [0.48600122],\n",
              "       [0.4859416 ],\n",
              "       [0.51063484],\n",
              "       [0.49066895],\n",
              "       [0.49077788],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.51536816],\n",
              "       [0.49956053],\n",
              "       [0.4859416 ],\n",
              "       [0.50842863],\n",
              "       [0.4859416 ],\n",
              "       [0.5065519 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49990684],\n",
              "       [0.5117156 ],\n",
              "       [0.48631236],\n",
              "       [0.48649198],\n",
              "       [0.5248653 ],\n",
              "       [0.49296108],\n",
              "       [0.49267465],\n",
              "       [0.4955315 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4962844 ],\n",
              "       [0.49169618],\n",
              "       [0.4859416 ],\n",
              "       [0.4894957 ],\n",
              "       [0.49115196],\n",
              "       [0.49144483],\n",
              "       [0.49535728],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5023602 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4866111 ],\n",
              "       [0.4893918 ],\n",
              "       [0.51686716],\n",
              "       [0.50661886],\n",
              "       [0.49952275],\n",
              "       [0.4859416 ],\n",
              "       [0.4875521 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49143377],\n",
              "       [0.5101571 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4975552 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5036469 ],\n",
              "       [0.4887105 ],\n",
              "       [0.5036206 ],\n",
              "       [0.4940221 ],\n",
              "       [0.48682088],\n",
              "       [0.4859416 ],\n",
              "       [0.4905755 ],\n",
              "       [0.48852122],\n",
              "       [0.4954725 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.50905675],\n",
              "       [0.5082957 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5221992 ],\n",
              "       [0.4859416 ],\n",
              "       [0.48611373],\n",
              "       [0.49603876],\n",
              "       [0.51112926],\n",
              "       [0.50187296],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5064883 ],\n",
              "       [0.4859416 ],\n",
              "       [0.491592  ],\n",
              "       [0.4906982 ],\n",
              "       [0.48889408],\n",
              "       [0.4859416 ],\n",
              "       [0.48795602],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.5154274 ],\n",
              "       [0.49449086],\n",
              "       [0.4883223 ],\n",
              "       [0.49689883],\n",
              "       [0.5140582 ],\n",
              "       [0.49845812],\n",
              "       [0.48785368],\n",
              "       [0.4859416 ],\n",
              "       [0.49473345],\n",
              "       [0.4897684 ],\n",
              "       [0.50725967],\n",
              "       [0.4859416 ],\n",
              "       [0.51098543],\n",
              "       [0.5002992 ],\n",
              "       [0.5090387 ],\n",
              "       [0.49889615],\n",
              "       [0.50107944],\n",
              "       [0.4880013 ],\n",
              "       [0.49038732],\n",
              "       [0.48618317],\n",
              "       [0.49833402],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.4859416 ],\n",
              "       [0.49148095]], dtype=float32)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "colab_type": "code",
        "id": "DbrU9QE0do6d",
        "outputId": "8ac2b07d-5c2d-4f50-e822-e3b8decbf62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 4ms/step - loss: 0.7045 - accuracy: 0.4930\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6987 - accuracy: 0.4960\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.5020\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5060\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.5110\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5140\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5140\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.4940\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.4930\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.4970\n",
            "16/16 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "#Import required packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# Getting the data ready\n",
        "# Generate train dummy data for 1000 Students and dummy test for 500\n",
        "#Columns :Age, Hours of Study & Avg Previous test scores\n",
        "np.random.seed(2018)\n",
        "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
        "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
        "labels = np.random.randint(2, size=(1000, 1))\n",
        "\n",
        "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=3, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Train the model and make predictions\n",
        "model.fit(train_data, labels, epochs=10, batch_size=32)\n",
        "\n",
        "#Make predictions from the trained model\n",
        "predictions = model.predict(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "colab_type": "code",
        "id": "x1joAQSIkbd7",
        "outputId": "6dd6ac91-ca68-4a42-8005-7ce593645faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "94/94 [==============================] - 2s 10ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6930 - val_accuracy: 0.5060\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5135\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6930 - val_accuracy: 0.5045\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6930 - val_accuracy: 0.5045\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5045\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5110 - val_loss: 0.6930 - val_accuracy: 0.5085\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 0.6926 - accuracy: 0.5157 - val_loss: 0.6930 - val_accuracy: 0.5060\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.6927 - accuracy: 0.5137 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 1s 9ms/step - loss: 0.6926 - accuracy: 0.5172 - val_loss: 0.6932 - val_accuracy: 0.5045\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.6927 - accuracy: 0.5197 - val_loss: 0.6929 - val_accuracy: 0.5140\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52a47b8160>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "# Generate dummy training dataset\n",
        "x_train = np.random.random((6000,10))\n",
        "y_train = np.random.randint(2, size=(6000, 1))\n",
        "\n",
        "# Generate dummy validation dataset\n",
        "x_val = np.random.random((2000,10))\n",
        "y_val = np.random.randint(2, size=(2000, 1))\n",
        "\n",
        "# Generate dummy test dataset\n",
        "x_test = np.random.random((2000,10))\n",
        "y_test = np.random.randint(2, size=(2000, 1))\n",
        "\n",
        "#Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=10,activation = \"relu\")) #Layer 1\n",
        "model.add(Dense(32,activation = \"relu\"))               #Layer 2\n",
        "model.add(Dense(16,activation = \"relu\"))               #Layer 3\n",
        "model.add(Dense(8,activation = \"relu\"))                #Layer 4\n",
        "model.add(Dense(4,activation = \"relu\"))                #Layer 5\n",
        "model.add(Dense(1,activation = \"sigmoid\"))             #Output Layer\n",
        "\n",
        "#Configure the model\n",
        "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dvPz99HQlCN-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "#Make predictions from the trained model\n",
        "predictions = model.predict(x_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "An Introduction to Deep Learning and Keras_syed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
